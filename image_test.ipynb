{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone.brain import compute_exact_duplicates\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define dataset paths and classes\n",
    "TRAIN_DIR = \"/Users/rohanreddy/Documents/fifty/intel-dataset/seg_train/seg_train\"\n",
    "TEST_DIR = \"/Users/rohanreddy/Documents/fifty/intel-dataset/seg_test/seg_test\"\n",
    "DATASET_NAME = \"intel_testfinal\"\n",
    "CLASSES = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
    "\n",
    "# Simple label mapping for ImageNet to Intel classes (approximate)\n",
    "# Extend this mapping based on your needs\n",
    "LABEL_MAPPING = {\n",
    "    \"castle\": \"buildings\", \"church\": \"buildings\", \"monastery\": \"buildings\", \n",
    "    \"palace\": \"buildings\", \"cinema\": \"buildings\", \"library\": \"buildings\",\n",
    "    \"barn\": \"buildings\", \"boathouse\": \"buildings\", \"greenhouse\": \"buildings\",\n",
    "    \"lakeside\": \"sea\", \"seashore\": \"sea\", \"liner\": \"sea\", \"yawl\": \"sea\",\n",
    "    \"dock\": \"sea\", \"pier\": \"sea\", \"fireboat\": \"sea\", \"lifeboat\": \"sea\",\n",
    "    \"container ship\": \"sea\", \"aircraft carrier\": \"sea\", \"trimaran\": \"sea\",\n",
    "    \"snowplow\": \"glacier\", \"drilling platform\": \"glacier\",\n",
    "    \"stupa\": \"mountain\", \"dome\": \"mountain\", \"obelisk\": \"mountain\",\n",
    "    \"street sign\": \"street\", \"streetcar\": \"street\", \"traffic light\": \"street\",\n",
    "    \"trolleybus\": \"street\", \"cab\": \"street\", \"passenger car\": \"street\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 14034/14034 [2.9s elapsed, 0s remaining, 4.6K samples/s]      \n",
      " 100% |███████████████| 3000/3000 [489.8ms elapsed, 0s remaining, 6.1K samples/s]      \n",
      "Loaded dataset with 17034 samples\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from both train and test directories\n",
    "try:\n",
    "    train_dataset = fo.Dataset.from_dir(\n",
    "        dataset_dir=TRAIN_DIR,\n",
    "        dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "        name=f\"{DATASET_NAME}_train\",\n",
    "        persistent=True\n",
    "    )\n",
    "    test_dataset = fo.Dataset.from_dir(\n",
    "        dataset_dir=TEST_DIR,\n",
    "        dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "        name=f\"{DATASET_NAME}_test\",\n",
    "        persistent=True\n",
    "    )\n",
    "    # Merge datasets\n",
    "    dataset = fo.Dataset(DATASET_NAME, persistent=True)\n",
    "    dataset.add_collection(train_dataset)\n",
    "    dataset.add_collection(test_dataset)\n",
    "    print(f\"Loaded dataset with {len(dataset)} samples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading jacobmarks/image-deduplication-plugin...\n",
      "  102.1Kb [453.3us elapsed, ? remaining, 220.0Mb/s] \n",
      "Skipping existing plugin '@jacobmarks/image_deduplication'\n"
     ]
    }
   ],
   "source": [
    "!fiftyone plugins download https://github.com/jacobmarks/image-deduplication-plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing filehashes...\n",
      " 100% |█████████████| 17034/17034 [2.3s elapsed, 0s remaining, 7.1K samples/s]      \n",
      "Found 18 duplicate samples\n",
      "Exported duplicates to duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find exact duplicates and tag for review\n",
    "try:\n",
    "    dups = compute_exact_duplicates(dataset)\n",
    "    duplicate_count = sum(len(dup_ids) for _, dup_ids in dups.items())\n",
    "    print(f\"Found {duplicate_count} duplicate samples\")\n",
    "    duplicate_data = []\n",
    "    for sample_id, dup_ids in dups.items():\n",
    "        for dup_id in dup_ids:\n",
    "            try:\n",
    "                sample = dataset[dup_id]  # Strong reference\n",
    "                sample.tags.append(\"duplicate\")\n",
    "                sample.save()\n",
    "                duplicate_data.append({\"id\": dup_id, \"filepath\": sample.filepath, \"ground_truth\": sample.ground_truth.label})\n",
    "            except Exception as e:\n",
    "                print(f\"Error tagging sample {dup_id}: {e}\")\n",
    "        # To delete duplicates (keeping one), uncomment:\n",
    "        # dataset.delete_samples(dup_ids[1:])  # Keep first sample, delete rest\n",
    "    # Export duplicates to CSV\n",
    "    if duplicate_data:\n",
    "        pd.DataFrame(duplicate_data).to_csv(\"duplicates.csv\", index=False)\n",
    "        print(\"Exported duplicates to duplicates.csv\")\n",
    "    gc.collect()  # Free memory\n",
    "except Exception as e:\n",
    "    print(f\"Error computing duplicates: {e}\")\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged 0 blurry samples\n"
     ]
    }
   ],
   "source": [
    "# Detect blurry images and tag for review\n",
    "def compute_blurriness(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"L\")\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        laplacian = torch.nn.functional.conv2d(\n",
    "            img_tensor.unsqueeze(0).unsqueeze(0),\n",
    "            torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=torch.float32).reshape(1, 1, 3, 3),\n",
    "            padding=1\n",
    "        )\n",
    "        return float(laplacian.var())\n",
    "    except:\n",
    "        return float('inf')  # Skip corrupted images\n",
    "\n",
    "blurry_count = 0\n",
    "blurry_data = []\n",
    "for sample in dataset:\n",
    "    try:\n",
    "        blurriness = compute_blurriness(sample.filepath)\n",
    "        sample[\"blurriness\"] = blurriness\n",
    "        if blurriness < 100:\n",
    "            sample.tags.append(\"blurry\")\n",
    "            blurry_count += 1\n",
    "            blurry_data.append({\"id\": sample.id, \"filepath\": sample.filepath, \"ground_truth\": sample.ground_truth.label, \"blurriness\": blurriness})\n",
    "        sample.save()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample {sample.id}: {e}\")\n",
    "print(f\"Tagged {blurry_count} blurry samples\")\n",
    "# To delete blurry images, uncomment:\n",
    "# dataset.delete_samples(dataset.match_tags(\"blurry\"))\n",
    "# Export blurry images to CSV\n",
    "if blurry_data:\n",
    "    pd.DataFrame(blurry_data).to_csv(\"blurry_images.csv\", index=False)\n",
    "    print(\"Exported blurry images to blurry_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 17034/17034 [7.5m elapsed, 0s remaining, 40.1 samples/s]      \n",
      "Tagged 1770 samples with wrong predictions\n",
      "Saved view 'wrong_predictions_view' with 1770 samples\n",
      "Exported wrong predictions to wrong_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Identify annotation inconsistencies and wrong predictions\n",
    "try:\n",
    "    # Apply model\n",
    "    model = foz.load_zoo_model(\"mobilenet-v2-imagenet-torch\")\n",
    "    dataset.apply_model(model, label_field=\"predictions\", batch_size=None)  # Disable batching\n",
    "\n",
    "    # Map ImageNet predictions to Intel classes\n",
    "    for sample in dataset:\n",
    "        try:\n",
    "            pred_label = sample.predictions.label\n",
    "            mapped_label = LABEL_MAPPING.get(pred_label, pred_label)  # Keep original if not mapped\n",
    "            sample.predictions.label = mapped_label\n",
    "            sample.save()\n",
    "        except Exception as e:\n",
    "            print(f\"Error mapping prediction for sample {sample.id}: {e}\")\n",
    "\n",
    "# Evaluate classifications\n",
    "# dataset.evaluate_classifications(\n",
    "#     pred_field=\"predictions\",\n",
    "#     gt_field=\"ground_truth\",\n",
    "#     method=\"top-k\",\n",
    "#     k=5,\n",
    "#     classes=CLASSES,  # Use the six Intel classes\n",
    "#     eval_key=\"eval_correct\"\n",
    "# )\n",
    "\n",
    "# Compute mistakenness\n",
    "# try:\n",
    "#     compute_mistakenness(dataset, pred_field=\"predictions\", label_field=\"ground_truth\", use_logits=False)\n",
    "#     if \"mistakenness\" not in dataset.get_field_schema():\n",
    "#         raise ValueError(\"Mistakenness field was not added to the dataset\")\n",
    "    \n",
    "#     # Tag high mistakenness samples and create view\n",
    "#     error_count = 0\n",
    "#     mistakes_data = []\n",
    "#     for sample in dataset.sort_by(\"mistakenness\", reverse=True)[:50]:\n",
    "#         sample.tags.append(\"potential_error\")\n",
    "#         sample.save()\n",
    "#         error_count += 1\n",
    "#         mistakes_data.append({\n",
    "#             \"id\": sample.id,\n",
    "#             \"filepath\": sample.filepath,\n",
    "#             \"ground_truth\": sample.ground_truth.label,\n",
    "#             \"predicted\": sample.predictions.label,\n",
    "#             \"mistakenness\": sample.mistakenness\n",
    "#         })\n",
    "#     print(f\"Tagged {error_count} samples with potential annotation errors\")\n",
    "    \n",
    "#     # Create and save view for annotation mistakes\n",
    "#     mistakes_view = dataset.match_tags(\"potential_error\")\n",
    "#     dataset.save_view(\"mistakes_view\", mistakes_view)\n",
    "#     print(f\"Saved view 'mistakes_view' with {len(mistakes_view)} samples\")\n",
    "    \n",
    "#     # Export annotation mistakes to CSV\n",
    "#     if mistakes_data:\n",
    "#         pd.DataFrame(mistakes_data).to_csv(\"annotation_mistakes.csv\", index=False)\n",
    "#         print(\"Exported annotation mistakes to annotation_mistakes.csv\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error in mistakenness computation: {e}. Skipping mistakenness-based tagging.\")\n",
    "\n",
    "    # Detect wrong predictions, create and save view\n",
    "    wrong_pred_count = 0\n",
    "    wrong_pred_data = []\n",
    "    for sample in dataset:\n",
    "        try:\n",
    "            pred_label = sample.predictions.label\n",
    "            gt_label = sample.ground_truth.label\n",
    "            if pred_label not in CLASSES:  # Skip unmapped predictions\n",
    "                continue\n",
    "            if pred_label != gt_label:\n",
    "                sample.tags.append(\"wrong_prediction\")\n",
    "                sample.save()\n",
    "                wrong_pred_count += 1\n",
    "                wrong_pred_data.append({\n",
    "                    \"id\": sample.id,\n",
    "                    \"filepath\": sample.filepath,\n",
    "                    \"ground_truth\": sample.ground_truth.label,\n",
    "                    \"predicted\": sample.predictions.label\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking prediction for sample {sample.id}: {e}\")\n",
    "    print(f\"Tagged {wrong_pred_count} samples with wrong predictions\")\n",
    "    \n",
    "    # Create and save view for wrong predictions\n",
    "    wrong_predictions_view = dataset.match_tags(\"wrong_prediction\")\n",
    "    dataset.save_view(\"wrong_predictions_view\", wrong_predictions_view, overwrite=True)\n",
    "    print(f\"Saved view 'wrong_predictions_view' with {len(wrong_predictions_view)} samples\")\n",
    "    \n",
    "    # Export wrong predictions to CSV\n",
    "    if wrong_pred_data:\n",
    "        pd.DataFrame(wrong_pred_data).to_csv(\"wrong_predictions.csv\", index=False)\n",
    "        print(\"Exported wrong predictions to wrong_predictions.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error computing wrong predictions: {e}\")\n",
    "    raise SystemExit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to FiftyOne on port 5151 at 127.0.0.1.\n",
      "If you are not connecting to a remote session, you may need to start a new session and specify a port\n",
      "Server version (1.7.0) does not match client version (1.7.1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:5151/?notebook=True&subscription=69b1d983-6737-4d7a-a01d-afdc393b8714\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x329bd1f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch FiftyOne App for visual review\n",
    "fo.close_app()  # Ensure clean session\n",
    "try:\n",
    "    session = fo.launch_app(dataset, address=\"127.0.0.1\", port=5151, auto=True)\n",
    "except Exception as e:\n",
    "    print(f\"Port 5151 failed: {e}. Trying port 5152.\")\n",
    "    session = fo.launch_app(dataset, address=\"127.0.0.1\", port=5152, auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:5151/?notebook=True&subscription=ad04b2b3-e059-4d9c-86b2-c35baccbe749\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x329abc050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set view to wrong predictions\n",
    "session.view = dataset.match_tags(\"wrong_prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
